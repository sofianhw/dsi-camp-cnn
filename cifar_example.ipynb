{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial 1: Classifying tiny images with a Convolutional Neural Network\n",
    "======================================\n",
    "\n",
    "Outline\n",
    "------------------------\n",
    "This interactive notebook shows how to do image classification with a Convnet. You can edit code in the code cells, and run it with `Shift+Return`. The notebook is read-only, so feel free to hack the code, and reload the page if something breaks. The tutorial covers how to:\n",
    "* Build a small convNet in neon.\n",
    "* Train it on the [Cifar10](https://www.kaggle.com/c/cifar-10) dataset. \n",
    "* Upload a new image, and classify it into one of the 10 categories.\n",
    "\n",
    "\n",
    "<img src=\"https://kaggle2.blob.core.windows.net/competitions/kaggle/3649/media/cifar-10.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up a model\n",
    "==================\n",
    "The pieces we need to set up a model are described in the [neon user guide](http://neon.nervanasys.com/docs/latest/index.html):\n",
    "* The CIFAR10 dataset.\n",
    "* layer configuration and a  [model](http://neon.nervanasys.com/docs/latest/models.html).\n",
    "* a compute [backend](http://neon.nervanasys.com/docs/latest/backends.html).\n",
    "* an [optimizer](http://neon.nervanasys.com/docs/latest/optimizers.html) to train the model.\n",
    "* [callbacks](http://neon.nervanasys.com/docs/latest/callbacks.html) to keep us updated about the progress of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We start by generating the backend:\n",
    "from neon.backends import gen_backend\n",
    "be = gen_backend(backend='cpu',             \n",
    "                 batch_size=128)\n",
    "\n",
    "# there is not much we can do with the backend right now, but if we\n",
    "# print it, it should tell us that we have a CPU backend object\n",
    "print be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a dataset\n",
    "-----------------\n",
    "More details about loading and generating datasets in our [documentation](http://neon.nervanasys.com/docs/latest/datasets.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The dataset is supplied in canned form, and will be downloaded \n",
    "# from the web the first time you run this. It just returns numpy\n",
    "# arrays with the pixel values, and class labels. \n",
    "from neon.data import CIFAR10\n",
    "cifar10 = CIFAR10()\n",
    "\n",
    "# to put the dataset into a format neon can understand, we create\n",
    "# a DataIterator instance. This moves the data onto the compute\n",
    "# device (e.g. GPU) and provides an iterator that returns training\n",
    "# batches. \n",
    "train_set = cifar10.train_iter\n",
    "test_set = cifar10.valid_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network Layers\n",
    "--------------\n",
    "Layer types are [documented here](http://neon.nervanasys.com/docs/latest/layers.html).\n",
    "It helps to make use of iPython tab completion to see available layers (e.g. `from neon.layers import TAB`) and to read the docstrings (e.g. using `Dataiterator? shift+return` syntax).\n",
    "\n",
    "Layer types included in neon:\n",
    "* Convolution\n",
    "* Bias\n",
    "* Activation\n",
    "* Pooling\n",
    "* Batch Normalization\n",
    "\n",
    "And for commonly used combinations neon provides shortcuts:\n",
    "* Conv = Convolution + Bias + Activation\n",
    "* Affine = Linear + Bias + Activation\n",
    "\n",
    "for this network, we are going to use one **Conv**, one **Pooling** and one **Affine** layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we create a model by assembling some layers\n",
    "from neon.layers import Conv, Affine, Pooling\n",
    "from neon.initializers import Uniform\n",
    "from neon.transforms.activation import Rectlin, Softmax\n",
    "init_uni = Uniform(low=-0.1, high=0.1)\n",
    "layers = [Conv(fshape=(5,5,16), init=init_uni, activation=Rectlin()),\n",
    "          Pooling(fshape=2, strides=2),\n",
    "          Conv(fshape=(5,5,32), init=init_uni, activation=Rectlin()),\n",
    "          Pooling(fshape=2, strides=2),\n",
    "          Affine(nout=500, init=init_uni, activation=Rectlin()),\n",
    "          Affine(nout=10, init=init_uni, activation=Softmax())]\n",
    "\n",
    "# set up model\n",
    "from neon.models import Model\n",
    "model = Model(layers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost function\n",
    "--------------\n",
    "Next we need a cost function to evaluate the output of the network. The cost function compares network outputs with ground truth labels, and produces and error that we can backpropagate through the layers of the network.\n",
    "\n",
    "For our binary classification task, we use a cross entropy cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting up the cost function\n",
    "from neon.layers import GeneralizedCost\n",
    "from neon.transforms import CrossEntropyMulti\n",
    "cost = GeneralizedCost(costfunc=CrossEntropyMulti())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer\n",
    "---------\n",
    "We now have a cost function that we want to minimize, typically by following \n",
    "the negative gradient of the cost. This is called gradient descent. We do this\n",
    "iteratively over small batches of the data set, making it stochastic gradient \n",
    "decesent (SGD). There are other [optimizers](http://neon.nervanasys.com/docs/latest/optimizers.html) such as\n",
    "* RMSProp\n",
    "* AdaDelta\n",
    "\n",
    "that are supported in neon, but often simple gradient descent works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up optimizer\n",
    "from neon.optimizers import GradientDescentMomentum, RMSProp\n",
    "optimizer = GradientDescentMomentum(learning_rate=0.005, \n",
    "                                    momentum_coef=0.9)\n",
    "#optimizer = RMSProp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks\n",
    "---------\n",
    "To provide feedback while the model is training, neon lets the user specify a set of callbacks that get evaluated at the end of every iteration (minibatch) or pass through the dataset (epoch). Callbacks include evaluating the model on a validation set or computing missclassification percentage. There are also callbacks for saving to disk and for generating visualizations. Here we will set up a progress bar to monitor training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up callbacks. By default sets up a progress bar\n",
    "from neon.callbacks.callbacks import Callbacks\n",
    "callbacks = Callbacks(model, train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model\n",
    "------------------\n",
    "Now all the pieces are in place to run the network. We use the fit function and pass it a dataset, cost, optmizer, and the callbacks we set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And  run the model\n",
    "model.fit(dataset=train_set,\n",
    "          cost=cost,\n",
    "          optimizer=optimizer,\n",
    "          num_epochs=5,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! If you made it this far you have trained a convolutional network in neon.\n",
    "\n",
    "Evaluating the model\n",
    "--------------------\n",
    "We can now compute the misclassification on the test set to see how well we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the performance on the supplied test set\n",
    "from neon.transforms import Misclassification\n",
    "error_pct = 100 * model.eval(test_set, metric=Misclassification())\n",
    "print 'Misclassification error = %.1f%%' % error_pct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By tweaking some of the hyperparameters (number of layers, adding dropout...) we can improve the performance.\n",
    "\n",
    "This was quite a lot of code! Generally, to set up a new model from scratch it is best to follow one of the examples from the neon/examples directory. It's easy to mix and match parts!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference\n",
    "=========\n",
    "Now we want to grab a new image from the internet and classify it through our network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# an image of a from I found on Wikipedia\n",
    "img_source = \"https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Atelopus_zeteki1.jpg/440px-Atelopus_zeteki1.jpg\"\n",
    "\n",
    "# download the image\n",
    "import urllib\n",
    "urllib.urlretrieve(img_source, filename=\"image.jpg\")\n",
    "\n",
    "# crop and resize to 32x32\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "img = Image.open('image.jpg')\n",
    "crop = img.crop((0,0,min(img.size),min(img.size)))\n",
    "crop.thumbnail((32, 32))\n",
    "plt.imshow(crop, interpolation=\"nearest\")\n",
    "crop = np.asarray(crop, dtype=np.float32)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataset with this image for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a minibatch with the new image \n",
    "import numpy as np\n",
    "from neon.data import ArrayIterator\n",
    "x_new = np.zeros((128,3072), dtype=np.float32)\n",
    "x_new[0] = crop.reshape(1,3072)/ 255\n",
    "\n",
    "inference_set = ArrayIterator(x_new, None, nclass=nclass, \n",
    "                             lshape=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get model outputs on the inference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes =[\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \n",
    "          \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "out = model.get_outputs(inference_set)\n",
    "classes[out[0].argmax()]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}